---
title: 那些年关于技术的未解之谜
categories: 基础技术知识
tags:
  - Spark
  - ElasticSearch
  - es
keywords: 'Spark,ElasticSearch,es'
id: 2019-03-01 16:53:21
date: 2019-03-01 16:53:21
updated: 2019-03-01 16:53:21
---




由于技术能力的限制，平时会遇到一些自己觉得非常诡异的问题，感觉到莫名其妙。其实到头来发现，归根结底还是自己的认知问题：可能是技术水平不够，或者考虑不周全，甚至是一些低级别的错误判断。总而言之，遇到这些问题后，有时候请教人、查资料之后仍旧不得解，只能先记录下来，留做备注说明，等待以后解决。当然，随着时间的流逝，有些问题可能就被忘记了，有些问题在之后的某一个时间点被解决了。本文就是要记录这些问题，并在遇到新问题或者解决老问题之后，保持更新。


<!-- more -->


# 常用链接


在这里先列出一些常用的网站链接，方便查看：
- es-hadoop 官网：https://www.elastic.co/guide/en/elasticsearch/hadoop/5.6/configuration.html ；
- x


# es-spark 读取 es 数据后 count 报错


使用 es-hadoop 组件，起 Spark 任务去查询 es 数据，然后过滤，过滤后做一个 count 算子，结果就报错了。而且，在报错后又重试了很多次（5次以上），一直正常，没法重现问题。这个任务需要经常跑，以前从来没遇到过这样的异常，初步怀疑是 es 集群不稳定，具体原因不得而知。

错误截图：
![报错信息截图](https://ws1.sinaimg.cn/large/b7f2e3a3gy1g0pyfelevwj20vj0mr0w0.jpg "报错信息截图")

完整错误信息如下（重要包名称被替换）：
````java
2019-02-26_15:01:44 [main] ERROR spokesman3.SpokesAndBrand:510: !!!!Spark 出错: org.codehaus.jackson.JsonParseException: Unexpected end-of-input in field name
 at [Source: org.apache.commons.httpclient.AutoCloseInputStream@2687cf14; line: 1, column: 17581]
org.elasticsearch.hadoop.rest.EsHadoopParsingException: org.codehaus.jackson.JsonParseException: Unexpected end-of-input in field name
 at [Source: org.apache.commons.httpclient.AutoCloseInputStream@2687cf14; line: 1, column: 17581]
	at org.elasticsearch.hadoop.rest.RestClient.parseContent(RestClient.java:171)
	at org.elasticsearch.hadoop.rest.RestClient.get(RestClient.java:155)
	at org.elasticsearch.hadoop.rest.RestClient.targetShards(RestClient.java:357)
	at org.elasticsearch.hadoop.rest.RestRepository.doGetReadTargetShards(RestRepository.java:306)
	at org.elasticsearch.hadoop.rest.RestRepository.getReadTargetShards(RestRepository.java:297)
	at org.elasticsearch.hadoop.rest.RestService.findPartitions(RestService.java:241)
	at org.elasticsearch.spark.rdd.AbstractEsRDD.esPartitions$lzycompute(AbstractEsRDD.scala:73)
	at org.elasticsearch.spark.rdd.AbstractEsRDD.esPartitions(AbstractEsRDD.scala:72)
	at org.elasticsearch.spark.rdd.AbstractEsRDD.getPartitions(AbstractEsRDD.scala:44)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1929)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1157)
	at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:440)
	at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:46)
	at com.package.to.class.SpokesAndBrand.getMention(SpokesAndBrand.java:508)
	at com.package.to.class.SpokesAndBrand.runCelebrityByBrand(SpokesAndBrand.java:185)
	at com.package.to.class.SpokesAndBrand.execute(SpokesAndBrand.java:116)
	at com.package.to.class.SpokesmanAnalyzer.execute(SpokesmanAnalyzer.java:162)
	at com.package.to.class.SpokesmanAnalyzeCli.execute(SpokesmanAnalyzeCli.java:154)
	at com.package.to.class.SpokesmanAnalyzeCli.start(SpokesmanAnalyzeCli.java:75)
	at com.package.to.class.util.AdvCli.initRunner(AdvCli.java:191)
	at com.package.to.class.job.client.BasicInputOutputSystemWorker.run(BasicInputOutputSystemWorker.java:79)
	at com.package.to.class.model.AbstractDataReportWorker.run(AbstractDataReportWorker.java:122)
	at com.package.to.class.buffalo.job.AbstractBUTaskWorker.runTask(AbstractBUTaskWorker.java:63)
	at com.package.to.class.report.cli.TaskLocalRunnerCli.start(TaskLocalRunnerCli.java:110)
	at com.package.to.class.util.AdvCli.initRunner(AdvCli.java:191)
	at com.package.to.class.report.cli.TaskLocalRunnerCli.main(TaskLocalRunnerCli.java:43)
Caused by: org.codehaus.jackson.JsonParseException: Unexpected end-of-input in field name
 at [Source: org.apache.commons.httpclient.AutoCloseInputStream@2687cf14; line: 1, column: 17581]
	at org.codehaus.jackson.JsonParser._constructError(JsonParser.java:1433)
	at org.codehaus.jackson.impl.JsonParserMinimalBase._reportError(JsonParserMinimalBase.java:521)
	at org.codehaus.jackson.impl.JsonParserMinimalBase._reportInvalidEOF(JsonParserMinimalBase.java:454)
	at org.codehaus.jackson.impl.Utf8StreamParser.parseEscapedFieldName(Utf8StreamParser.java:1503)
	at org.codehaus.jackson.impl.Utf8StreamParser.slowParseFieldName(Utf8StreamParser.java:1404)
	at org.codehaus.jackson.impl.Utf8StreamParser._parseFieldName(Utf8StreamParser.java:1231)
	at org.codehaus.jackson.impl.Utf8StreamParser.nextToken(Utf8StreamParser.java:495)
	at org.codehaus.jackson.map.deser.std.UntypedObjectDeserializer.mapObject(UntypedObjectDeserializer.java:219)
	at org.codehaus.jackson.map.deser.std.UntypedObjectDeserializer.deserialize(UntypedObjectDeserializer.java:47)
	at org.codehaus.jackson.map.deser.std.UntypedObjectDeserializer.mapArray(UntypedObjectDeserializer.java:165)
	at org.codehaus.jackson.map.deser.std.UntypedObjectDeserializer.deserialize(UntypedObjectDeserializer.java:51)
	at org.codehaus.jackson.map.deser.std.UntypedObjectDeserializer.mapArray(UntypedObjectDeserializer.java:165)
	at org.codehaus.jackson.map.deser.std.UntypedObjectDeserializer.deserialize(UntypedObjectDeserializer.java:51)
	at org.codehaus.jackson.map.deser.std.MapDeserializer._readAndBind(MapDeserializer.java:319)
	at org.codehaus.jackson.map.deser.std.MapDeserializer.deserialize(MapDeserializer.java:249)
	at org.codehaus.jackson.map.deser.std.MapDeserializer.deserialize(MapDeserializer.java:33)
	at org.codehaus.jackson.map.ObjectMapper._readValue(ObjectMapper.java:2704)
	at org.codehaus.jackson.map.ObjectMapper.readValue(ObjectMapper.java:1286)
	at org.elasticsearch.hadoop.rest.RestClient.parseContent(RestClient.java:166)
	... 29 more
2019-02-26_15:01:44 [main] INFO rdd.JavaEsRDD:58: Removing RDD 3086 from persistence list
````

# Hexo 生成 html 静态页面目录锚点失效


我这些所有的博客文档是先写成 Markdown 文件，然后使用 Hexo 渲染生成 html 静态页面，再发布到 GitHub Pages 上面，还有一些是发布到我自己的 VPS 上面（为了百度爬虫）。

但是最近我发现一个现象，有一些文章的锚点无效，也就是表现为目录无法跳转，例如想直接查看某一级目录的内容，在右侧的**文章目录**中直接点击对应的标题，不会自动跳转过去。这个问题我发现了很久，但是一直没在意，也没有找到原因。最近才碰巧发现是因为标题内容里面有空格，这才导致生成的 html 静态页面里面的锚点失效，我随机又测试了几次其它的页面，看起来的确是这样。下面列出一些示例：

```
https://www.playpi.org/2019022501.html ，Hexo 踩坑记录的
https://www.playpi.org/2018121901.html ，js 字符串分割方法
https://www.playpi.org/2019020701.html ，itchat 0-初识
```

但是，我又发现其他人的博客，目录标题内容中也有空格，却可以正常跳转，我很疑惑。现在我猜测是 Hexo 的问题，或者哪里需要配置，等待以后的解决方法吧。别人的博客示例：https://blog.itnote.me/Hexo/hexo-chinese-english-space/ 。


# x


x

