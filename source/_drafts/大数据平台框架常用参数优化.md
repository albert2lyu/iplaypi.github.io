---
title: 大数据平台框架常用参数优化
id: 2019-12-19 22:54:12
date: 2019-12-19 22:54:12
updated: 2019-12-19 22:54:12
categories:
tags:
keywords:
---

2019121901
大数据技术知识
Hadoop,HBase,Elasticsearch,HDFS,MapReduce,Spark,Storm,Kafka,Zookeeper


本文记录大数据平台框架的一些常用参数，这些参数基本是我见过的或者实际使用过的，我会列出参数的含义以及使用效果，具有一定的参考意义。当然，根据实际的场景不同，参数值并不能随便设置为一样，必须要考虑到实际的情况，否则可能没有效果，或者具有反作用。

<!-- more -->


# Hadoop


## HDFS

待整理

## MapReduce


- `map` 并发大小：`mapreduce.job.running.map.limit`，可以设置大点，50、100随便
- `map` 内存大小：`mapreduce.map.memory.mb`，单位为 `MB`，一般 `4GB` 够用
- `reduce` 启动延迟：`mapred.reduce.slowstart.completed.maps`，表示 `reduce` 在 `map` 执行到什么程度可以启动，例如设置为 `1.0` 表示等待 `map` 全部完成后才能执行 `reduce`
- `reduce` 内存大小：`mapreduce.reduce.memory.mb`，单位为 `MB`，要根据实际情况设置，一般 `4GB` 够用
- `reduce` 虚拟内存：`yarn.nodemanager.vmem-pmem-ratio`，一般2-5即可
- `reduce` 并发大小：`mapreduce.job.running.reduce.limit`，一般5-10个够用【根据业务场景、机器资源而定】


# HBase


待整理


# Elasticsearch


1、刷新频率
2、每个节点只分配一个分片
3、备份数
4、每个索引大小
5、磁盘使用占比


# Spark


- 序列化方式：`spark.serializer`，可以选择：`org.apache.spark.serializer.KryoSerializer`
- `executor` 附件参数：`spark.executor.extraJavaOptions`，例如可以添加：`-Dxx=yy`【如果仅仅在 `driver` 端设置，`executor` 是不会有的】


# Storm


待整理


# Kafka


消息保存天数
外网集群可以访问


# Zookeeper


待整理

