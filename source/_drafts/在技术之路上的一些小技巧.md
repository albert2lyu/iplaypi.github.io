---
title: 在技术之路上的一些小技巧
id: 2020-03-12 01:26:47
date: 2020-02-13 01:26:47
updated: 2020-02-13 01:26:47
categories:
tags:
keywords:
---


2020021301
基础技术知识
Python,Java


# Python


`Python` 是一种脚本语言，想要运行 `Python` 脚本就需要先安装 `Python` 环境【就像运行 `Java` 程序需要 `JRE` 一样】，安装后别忘记配置环境变量。

官方网站：[python](https://www.python.org/downloads) 。

唯一需要注意的是安装时先核对脚本的语法，是安装 `v2.7.X` 版本还是 `v3.X` 版本，它们的语法有时候不兼容，导致脚本无法跑通。

## 虚拟环境

在某个项目中，使用 `Python` 构造 `Elasticsearch` 请求获取结果数据，但是脚本的内容是针对 `Python v3.X` 环境的，而服务器上是 `Python v2.7` 版本的环境，而且个人没有权限更改【如果自己通过编译安装指定的版本，后续使用时如果缺失第三方模块还是需要手动安装，如果又引发模块之间的依赖，手动安装过程会崩溃的】，所以可以在服务器上面虚拟一个指定版本的 `Python` 环境出来。

```

-- 在任意目录，虚拟出 Python 2.7 环境
virtualenv py2.7
-- 进入环境
cd py2.7/
-- 激活环境
source bin/activate
-- 如果缺失第三方模块，直接安装即可
pip install requests
-- 取消环境
source bin/deactive
```

## 缓存问题

假如跑一个脚本，把输出重定向到一个文件中：`nohup python test.py > nohup.out 2>&1 &`，结果发现 `nohup.out` 中显示不出来 `python` 程序中 `print` 的内容【或者是不及时显示，隔一段时间才会有一点内容】。

这是因为 `python` 的输出有缓冲机制，导致我们从 `nohup.out` 中并不能够马上看到输出。其实运行 `python` 脚本的时候有个 `-u` 参数，使得 `python` 不启用缓冲，把程序中的输出内容实时输出到文件：`nohup python -u test.py > nohup.out 2>&1 &` 。

## 编码问题

`python` 的 `chardet` 模块，可以查看字符串的编码：`chardet.detect(data)` 。

## 处理文本文件

在处理 `csv` 文件时，遇到异常：`Error: field larger than field limit <131072>`，这其实是因为 `Python` 读取 `csv` 文件时有一个默认设置，某列的内容最大长度为131072【基于 `Python v2.5`】。

重点在于 `Error: field larger than field limit <131072>`，是因为 `csv` 文件中的某个字段的长度大于 `csv` 框架能处理的最大长度，需要在文件头加上参数配置代码：`csv.field_size_limit(sys.maxint)` ，这样就可以支持 `int` 的最大值所对应的长度了。

此外，由于 `csv` 文件的特殊性，`csv` 是特定分隔符分隔的文本文件，可能会导致内容混乱的状况，比如某一列包含了大量的换行符【又没有使用双引号封装起来】，会导致 `csv` 文件认为就是多行数据，这样这些行都是错误的数据【因为列数不够】，如果有连续的换行符，会导致空白行出现，`Python` 也会报错：`line contains NULL byte` 。


# Excel 的知识


对于分析人员，经常会用到 `Excel` 工具，用来看数据，或者操作数据。

但是，有时候文本内容过多，不再适合使用 `Excel` 操作了，不仅很卡，而且有崩溃的风险。

根据我的经验，以最多5万行内容，最大 `20MB` 为好，如果是 `Mac OS` 系统，需要更少。

下面列举一下 `Excel` 支持的内容上限：

`Excel` 2003 支持的最大行数是65536，`Excel` 2007支持的最大行数是1048576 。

`Excel` 2003 支持的最大列数是256，`Excel` 2007 以及以上支持的最大列数是16384 。


# 文件编码转换工具


`iconv` 需要单独安装：

```
-- 转换文件内容编码，从 gb18030 转到 utf-8
iconv --list 查看支持的编码
iconv -f gb18030 -t utf-8 oldfile -o newfile

-- 查看文件编码内容简要信息
file filename
```


# 文件名编码转换工具


在 `Linux` 系统中，如果把一个以中文命名的文件上传上去【特别是从 `Windows` 系统上传上去】，文件名可能会乱码，导致无法使用 `Shell` 操作文件，此时可以使用 `xx` 工具转换文件名的编码。

`convmv` 需要单独安装：

```
-- 转换文件名编码，从 utf-8 转到 gbk
convmv --list 查看支持的编码
convmv -f utf-8 -t gbk filename 显示效果
convmv -f utf-8 -t gbk --notest filename 真的转换

-- 查看文件编码内容简要信息
file filename
```


# 常用命令


## Shell

### 负载查看

对于操作系统上面的进程导致的机器负载升高，可以查看到底是哪个进程或者线程导致的：

```
xxx
yyy
```

### 进程查看

查看某个进程的启动目录：

```
-- 筛选进程名称，获取 pid
jps | grep 'process name'
-- 根据 pid 查看目录
pwdx 'pid'
-- 进入目录
cd 'dir'
```

### 使用 sed 操作文本文件

搜索替换之类的：

```
把文件中的 xxx 全部替换为 yyy，不带 -i 参数直接输出内容，不会更改文件
sed -i "s/xxx/yyy/g" your_file

在文件第 n 行前插入内容 xxx，不带 -i 参数直接输出内容，不会更改文件
注意 Linux 中以换行符 LF 作为一行的判断条件，所以指定不存在的行号时无法插入数据
sed -i "ni\xxx" your_file

输出文件的第 n 到 m 行内容
sed -n "n,mp" your_file
```

### 查看 Linux 系统的发行版本

`lsb_release -a`，该命令适用于所有 `Linux` 系统，会显示出完整的版本信息，包括 `Linux` 系统的名称，如：`Debian`、`Ubuntu`、`CentOS` 等，和对应的版本号，以及该版本的代号，例如在 `Debian 8` 中将会显示代号 `jessie`。

```
输出示例：
No LSB modules are available.
Distributor ID:	Ubuntu
Description:	Ubuntu 14.04.6 LTS
Release:	14.04
Codename:	trusty
```

`cat /etc/issue`，该命令适用于所有的 `Linux` 系统，显示的版本信息较为简略，只有系统名称和对应的版本号。

```
输出示例：
Ubuntu 14.04.6 LTS \n \l
```

`cat /etc/redhat-release`，该命令仅适用于 `Redhat` 系列的 `Linux` 系统，显示的版本信息也较为简略。

```
输出示例：
CentOS release 6.10 (Final)
```

`uname -a`、`cat /proc/version`，可以查看 `Linux` 的内核版本：

```
输出示例1：
Linux wufazhuce 3.13.0-32-generic #57-Ubuntu SMP Tue Jul 15 03:51:08 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux

输出示例2：
Linux version 3.13.0-32-generic (buildd@kissel) (gcc version 4.8.2 (Ubuntu 4.8.2-19ubuntu1) ) #57-Ubuntu SMP Tue Jul 15 03:51:08 UTC 2014
```

### split 拆分文件

把文件按照60行一个文件进行拆分，拆分后的文件以 `data_` 作为前缀，以2位数字作为后缀：

```
split -l 60 your_file -d -a 2 data_

拆分后的文件为 data_00、data_01、data_02 等等
```

### curl 请求网络

可以模拟请求，传输参数：

```
POST 请求，参数放在 seeds中
curl --location --request POST 'url' \
--header 'content-type: application/x-www-form-urlencoded; charset=UTF-8' \
--header 'Content-Type: application/x-www-form-urlencoded' \
--data-urlencode 'seeds=[{"keyword":"王者荣耀", "TOP_PAGE": "100"},{"keyword":"LOL", "TOP_N": "100"}]'

GET 请求，获取信息
curl --location --request GET url'

POST 请求，参数放在文件中
curl -X POST --data-binary @your_file url
```

查询 `Elasticsearch` 的数据：

```
-- 查询指定索引、指定类型的数据,返回1条数据，格式化结果
curl -X POST 'dev:9202/your_index/your_type/_search?pretty' -d '
{
  "query": { "match_all": {} },"size":1
}'
```

## Kafka

查看 `topic` 信息：

```
kafka-topics.sh --list --zookeeper dev:2181
```

生产数据：

```
kafka-console-producer.sh --topic your_topic --broker-list dev:9092
```

消费数据：

```
kafka-console-consumer.sh --zookeeper dev:2181 --topic your_topic
```

查看 `topic` 状态：

```
kafka-topics.sh --zookeeper dev:2181 --describe --topic your_topic
```

查看消费情况【消费组消费量、积压量、生产量】：

```
kafka-consumer-offset-checker.sh --zookeeper dev:2181 --group your_group --topic your_topic

如果上述脚本不可用，可以直接引用类
kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --group your_group --topic your_topic --zkconnect dev:2181
```

## Zookeeper

操作：

```
登录
zkCli.sh -server ip:port

退出
quit
```

## HBase

`HBase` 操作：

```
登录
hbase shell

帮助文档
!help

退格
ctrl + Backspace

退出
!quit

查看表信息
!list

获取数据
get '表名称','pk值'

扫描数据
scan '表名称',{LIMIT => 5}
```

`phoenix` 操作：

```
登录
phoenix-client/bin/sqlline.py dev:2181:/hbase-unsecure

帮助文档
!help

退出
!quit

查看表信息
!tables

查询数据
select * from "表名称" where "pk"='pk值';
select * from "表名称" limit 5;

导出数据
-- 格式化输出
!outputformat csv
-- 设置导出文件到 data.csv
!record data.csv
-- 查询需要导出的数据
select * from "表名称" limit 1000;
-- 完成导数操作
!record

格式化显示
!outputformat vertical
!outputformat csv
!outputformat table
```


# 大数据任务调度系统


## yarn

### 移动队列

在资源紧张的情况下，可以手动移动 `Spark` 任务的队列，合理利用空闲的资源。

如果 `yarn` 队列没有资源了，而自己又有 `Spark` 任务需要跑，在提交 `Spark` 任务后，可以看到任务在等待分配资源，此时可以把 `Spark` 任务移动到别的空闲队列去【也可以在提交 `Spark` 任务的时候指定队列】。

或者某些运行耗时比较长的任务，也可以先移动到别的空闲队列跑，释放自己业务的队列资源给其它任务使用。前提是确保不影响别的队列的正常使用，不能长久占用别人的队列。

使用 `yarn` 自带的命令：

```
--指定 Spark 任务的 applicationId，以及目标队列名称
--注意用户权限
yarn application -movetoqueue applicationId -queue queueName
```

如果不熟悉这些命令，可以使用 `yarn -help`、`yarn application -help` 等命令查看帮助说明文档。

### 取消任务

如果想 `kill` 掉一个正在 `yarn` 环境上运行的 `Spark` 任务，可以直接使用 `kill` 命令：

```
--指定 Spark 任务的 applicationId
yarn application -kill applicationId
```

当然，如果使用的 `yarn-client` 模式提交任务，并且有权限看到 `Driver` 端的进程，也可以直接使用 `Linux` 的命令 `kill` 掉进程【不够优雅】。

### 下载日志

下载已经完成的 `Spark` 任务的文本日志，在 `Saprk` 任务的 `UI` 界面，可以看到 `Excutor` 的日志，但是当日志多的时候，看起来不方便，搜索就更不用说了。

当任务完成之后，可以使用 `yarn` 命令下载文本日志进行查看、分析：

```
--指定 Spark 任务的 applicationId，所属用户
yarn logs -applicationId applicationId -appOwner userName
```

注意，由于用户权限的问题，在下载日志之前需要切换用户，否则获取不到日志或者抛出权限相关错误：

```
--切换用户，根据实际情况而定
--决定着去哪个目录获取日志文件
export HADOOP_USER_NAME=xxx
```

